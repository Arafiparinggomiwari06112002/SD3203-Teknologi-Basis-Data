Nama : A Rafi Paringgom Iwari
NIM : 121450039

# Pendahuluan
Pada artikel yang diberikan terdapat tiga cara utama yaitu dengan format PNG, lightning memory-mapped databases (LMDB), dan dengan hierarchical data format (HDF5) yang digunakan dalam melakukan storing dan pengaksesan images dengan menggunakan python. Terdapat beberapa langkah eskperimental yang dilakukan diantaranya persiapan, stroing satu gambar, storing banyak gambar, membaca satu gambar, membaca banyak gambar dan evaluasi. Pada artikel ini fokus utama ditujukan pada pembandingan pada proses storing dan pengaksesan pada tiga metode tersebut.
# Persiapan
Pada bagian persiapan digunakan kumpulan  gambar yang dimabil dari Canadian Institute for Advanced Research (CIFAR-10) yang terdiri dari 60.000 gambar berwarna dengan ukuran 32x32 pixel, yang telah diserialisasi dalam batch dengan cPicle sehingga tidak dapat dibaca oleh manusia, sehingga digunakan kode python yang dapat memuat gambar tersebut dalam disk.
# Kode untuk  menghapus masing-masing dari lima file batch dan memuat semua gambar ke dalam array NumPy

import numpy as np
import pickle
from pathlib import Path

# Path to the unzipped CIFAR data
data_dir = Path("data/cifar-10-batches-py/")

# Unpickle function provided by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}")

# dengan demikian gambar telah berada pada RAM dan siap dimanipulasi.
# Pengaturan untuk menyimpan gambar di disk
Pada artikel ini diberikan panduan dalam persiapan enviroment untuk dapat melakukan storing image pada disk, beberapa package yang perlu dipersiapkan seperti
# Pillow
$ pip install Pillow
# Conda
$ conda install -c conda-forge pillow
# yang disarankan pada versi python 3.x
# Memulai dengan LMBD
LMBD sering disebut dengan Lightning Database didasarakan kecepatanya dalam memetakan file dalam memory. LMBD memiliki struktur grafik mirip tree yang tersimpan dalam memori dimana tiap elemen kunci direpresentasikan sebagai node atau simpul dan tiap simpul memiliki child, node pada level yang setingkat akan dihubungkan secara traversal yang cepat. Kinerja dari LMBD yang efisien bergantung pada sistem file yang mendasarinya dan implementasinya. LMBD cukup efisien karena memetakan file pada memory, sehingga mengembalikan penunjuk langsung ke alamat memori dari kunci dan nilai , tanpa perlu menyalin apa pun di memori seperti yang dilakukan kebanyakan basis data lainnya.
# Memulai dengan HDF5
Meruapakan singkatan dari Hierarchical Data Format, format file yang biasa disebut HDF4 atau HDF5, HDF ini merupakan format data ilmiah yang portabel dan ringkas yang berasal dari National Center for Supercomputing Applications. File HDF terdiri dari kumpulan data yang berisi array multidimensi ( ukuran dan tipe apa pun dapat disimpan sebagai kumpulan data) dan grup yang merupakan kumpulan dari kumpulan data itu sendiri. 
# Menyimpan Satu Gambar
Untuk kepentingan eksperimen dilakukan perbandingan kinerja antara berbagai jumlah file, dengan faktor 10 dari satu gambar hingga 100.000 gambar. Karena lima kumpulan CIFAR-10 berjumlah 50.000 gambar, dapat digunakan setiap gambar dua kali untuk mendapatkan 100.000 gambar. Diperlukan folder untuk menyimpan file gambar dan path direktori dari ketiga variabel, yang dikodekan sebagai berikut
from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
# Menyimpan ke disk
Gambar yang sebelumya terdapat dalam memory dalam bentuk numpy array akan disimpan ke disk sebagai format png, denga  penamaan image ID yang dapat dilakukan dengan kode berikut
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
ketika menyimpan gambar ke dalam disk dan perlu menyimpan metadata terkait, salah satu solusinya adalah dengan mengkodekan metadata tersebut ke dalam nama file gambar itu sendiri. Ini menghilangkan kebutuhan untuk menyimpan metadata dalam file terpisah, tetapi memiliki kelemahan karena memaksa untuk memproses semua file setiap kali perlu mengakses metadata. Alternatifnya adalah menyimpan metadata dalam file terpisah, seperti file CSV, yang memungkinkan untuk mengelola metadata secara terpisah dari gambar dan mengaksesnya tanpa harus memuat gambar itu sendiri. Dalam contoh tersebut, label gambar disimpan dalam file CSV terpisah untuk memungkinkan eksperimen dengan label tanpa harus memproses gambar secara langsung.
# Menyimpan dalam LMBD
LMDB ialah sistem penyimpanan nilai kunci di mana setiap entri disimpan sebagai array byte. Dalam konteks kita, kunci akan menjadi pengidentifikasi unik untuk setiap gambar, dan nilainya akan menjadi gambar itu sendiri. Keduanya, kunci maupun nilai, diharapkan berupa string, sehingga penggunaan umum adalah membuat serial nilai sebagai string dan kemudian membatalkan serialisasinya saat membacanya kembali. Anda dapat menggunakan pickle untuk melakukan serialisasi. Objek Python apa pun dapat dibuat serial, sehingga disarankan untuk juga menyertakan data meta gambar ke dalam database. Hal ini menghindarkan kesulitan dalam melampirkan kembali metadata ke data gambar saat memuat kumpulan data dari disk. Untuk dapat membuat Class untuk gambar dan meta datanya lihat kode berikut ini
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary 
        # for this dataset, but some datasets may include images of 
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
Karena LMDB dipetakan dengan memori, database baru perlu mengetahui berapa banyak memori yang diperkirakan akan digunakan, yang disebut sebagai map_size. Meskipun relatif mudah dalam kasus tertentu, hal ini dapat menjadi masalah besar dalam situasi lain, yang akan dijelaskan lebih lanjut di bagian selanjutnya. Operasi baca dan tulis dengan LMDB dilakukan dalam transaksi, mirip dengan database tradisional, yang terdiri dari sekelompok operasi pada database

dengan demikian kode untuk menyimapan satu gambar dengan LMBD 
import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
# Menyimpan dengan HDF5
Berikut kode penyimpanan HDF5 dengan dua data yaitu, satu untuk gambar dan satu lagi untuk meta datanya
import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
# Eksperimen untuk Menyimpan Satu Gambar
Ketiga fungsi metode tersebut dapat  dimasukan dalam kamus yang dapat dipanggila sewaktu-waktu
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
Dengan demikian proses percobaan untuk menyimpan satu gambar dengan tiga cara tersebut melalui kode berikut.
from timeit import timeit

store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
dihasilakn metode Disk memakan waktu 1.915 micro detik dengan penyimanan 8rb, LMBD selama 1.203 Mili detik dengan penyimpanan 32rb dan HDF5 selama 8.243 micro detik dengan penyimpanan 8rb.
# Menyimpan Banyak Gambar
Untuk melakukan percobaan ini dilakukan modifikasi pada kode 
store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before — but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
Setelah langkah tersebut dilakukan selanjutnya diperlukan persiapan pada kumpulan data
cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
Selanjtunya dilakukan eksperimen untuk proses storing image dalam jumlah banyak
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
Berdasarakan Grafik hasil percobaan ini Grafik pertama memperlihatkan perbandingan waktu penyimpanan antara metode normal dan metode yang tidak disesuaikan, dengan menyoroti perbedaan drastis antara penyimpanan ke file .png dan menggunakan LMDB atau HDF5. Grafik kedua menunjukkan perubahan waktu secara logaritmik, menyoroti bahwa HDF5 memiliki awal yang lebih lambat dibandingkan dengan LMDB, tetapi dengan jumlah gambar yang lebih besar, hasilnya sedikit lebih cepat. Meskipun hasil pastinya dapat bervariasi tergantung pada mesin yang digunakan, ini adalah alasan mengapa LMDB dan HDF5 layak dipertimbangkan untuk digunakan.
Untuk mendapatkan tampilan dari grafik ini dapat digunakan kode brikut
import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)
# Membaca satu gambar
Untuk dapat membaca dari disk dengan format png digunakan kode berikut
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label
Untuk proses read dengan metode LMBD 
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label
terkahir untuk metode HDF5
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label
Dilkaukan proses pembuatan kamus kembali untuk proses read data
_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
# Eskperimen untuk membaca satu gambar 
Berikut kode eskperimennya
from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
Didapatkan hasil bahwa proses read gambar dengan metode  Disk menghabiskan waktu 1.6187 mili detik, LMBD 4.52063 mili detik dan HDF5 1.98036 mili detik. 
# Membaca Banyak Gambar 
Proses pembacaan banyak gamabr dikodekan dengan kode berikut
def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))

    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels

def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object 
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels

def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")

    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")

    return images, labels

_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)
Kemudian kode eskperimennya sebagai berikut
from timeit import timeit

read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=1,
            globals=globals(),
        )
        read_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}")
Berdasarkan hasil grafik, grafik hasil tersebut menampilkan perbandingan waktu baca antara metode normal dan metode yang tidak disesuaikan, menyoroti perbedaan drastis antara membaca dari file .png dan menggunakan LMDB atau HDF5. Sebaliknya, grafik di bawah menunjukkan variasi waktu dalam skala logaritmik, menyoroti perbedaan relatif dengan jumlah gambar yang lebih sedikit. Grafik tersebut menunjukkan bahwa HDF5 memiliki kinerja awal yang lebih lambat, tetapi dengan jumlah gambar yang lebih besar, secara konsisten menjadi lebih cepat dibandingkan dengan LMDB, dengan perbedaan yang kecil.
Selanjutnya untuk mendapatkan plot waktu read data digunakan kode berikut
disk_x_r = read_many_timings["disk"]
lmdb_x_r = read_many_timings["lmdb"]
hdf5_x_r = read_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to read",
    "Read time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to read",
    "Log read time",
    log=True,
)
Saat Anda menyimpan gambar sebagai file .png, terdapat perbedaan besar antara waktu penulisan dan pembacaan. Namun, dengan LMDB dan HDF5, perbedaan tersebut tidak terlalu signifikan. Secara keseluruhan, meskipun waktu pembacaan lebih penting daripada waktu penulisan dalam banyak kasus, terdapat argumen kuat untuk menyimpan gambar menggunakan LMDB atau HDF5. Hal ini karena kedua format tersebut menawarkan kinerja yang lebih seimbang antara waktu penulisan dan pembacaan, serta kemampuan untuk menyimpan metadata terkait gambar secara efisien. Dengan menggunakan LMDB atau HDF5, Anda dapat memanfaatkan keuntungan dari struktur penyimpanan yang dioptimalkan untuk aplikasi yang memerlukan akses cepat dan efisien terhadap data gambar.
# Mempertimbangkan Penggunaan Disk
Berdasarkan gamabr yang disedikan untuk perbandingan ruang disk yang digunakan setiap metode untuk setiap jumlah gambar
HDF5 dan LMDB, meskipun menawarkan kinerja yang baik dalam hal penyimpanan dan pengambilan gambar, menggunakan lebih banyak ruang disk dibandingkan dengan menyimpan gambar dalam format .png yang normal. Faktor utama yang memengaruhi penggunaan disk kedua metode adalah ukuran data yang disimpan, serta fitur-fitur sistem operasi yang dimanfaatkan untuk mencapai efisiensi penyimpanan. Meskipun LMDB menggunakan caching dan memanfaatkan ukuran halaman OS untuk efisiensi penyimpanan, gambar yang lebih besar cenderung menghasilkan penggunaan disk yang lebih besar karena gambar tidak akan muat di dalam halaman daun LMDB, menyebabkan banyak halaman meluap. Sementara itu, pengalaman praktis menunjukkan bahwa untuk gambar dengan ukuran yang lebih besar, seperti 256x256x3 atau 512x512x3 piksel, HDF5 seringkali sedikit lebih efisien dalam penggunaan disk dibandingkan dengan LMDB. Hal ini membuktikan pentingnya mempertimbangkan ukuran data dan karakteristik aplikasi saat memilih metode penyimpanan yang tepat untuk kebutuhan Anda.
# Kesimpulan 
Tiap sistem penyimpanan baik dengan format png, LMBD dan HDF5 memiliki kelmahan masing-masing, namun Penting untuk dipahami bahwa dalam LMDB, data baru ditulis tanpa menimpa atau memindahkan data yang sudah ada. Keputusan desain ini memungkinkan operasi pembacaan yang sangat cepat, seperti yang diamati dalam eksperimen kami, dan juga menjamin integritas dan keandalan data tanpa memerlukan penyimpanan log transaksi tambahan. Dengan pendekatan ini, LMDB mencapai keseimbangan yang optimal antara kinerja, integritas data, dan keandalan operasi, menjadikannya pilihan yang kuat untuk aplikasi yang memerlukan akses cepat dan aman terhadap data. Sedangakan saat kondisi kinerja tinggi HDF5 akan sangat baik digunakan. Secara umum, benar bahwa dalam LMDB, Anda mungkin mendapatkan kinerja yang lebih baik ketika mengakses item secara berurutan berdasarkan kunci. Ini karena pasangan nilai-kunci disimpan dalam memori yang diurutkan secara alfanumerik berdasarkan kunci, sehingga akses berurutan dapat dilakukan dengan cepat dan efisien. Di sisi lain, untuk HDF5, mengakses rentang yang besar dalam kumpulan data akan berkinerja lebih baik daripada membaca setiap elemen satu per satu. Hal ini disebabkan oleh struktur penyimpanan HDF5 yang memungkinkan akses cepat ke rentang data, mengurangi overhead yang terkait dengan membaca setiap elemen secara terpisah. Dalam kedua kasus, pemahaman tentang struktur dan cara kerja dari masing-masing format penyimpanan sangat penting untuk memaksimalkan kinerja dalam penggunaan sehari-hari.
